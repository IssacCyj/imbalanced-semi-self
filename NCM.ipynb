{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89deda55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import models\n",
    "from utils import *\n",
    "from dataset.imbalance_cifar import ImbalanceCIFAR10, ImbalanceCIFAR100\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model_path = 'checkpoint/cifar10_resnet32_Focal_None_exp_0.01_stage1/ckpt.best.pth.tar'\n",
    "model_path = 'checkpoint/cifar10_resnet32_LDAM_None_exp_0.01_stage1/ckpt.best.pth.tar'\n",
    "model_path = 'checkpoint/cifar10_resnet32_LDAM_Resample_exp_0.01_stage2_freeze/ckpt.best.pth.tar'\n",
    "# model_path = 'checkpoint/cifar10_resnet32_LDAM_DRW_exp_0.01_stage2/ckpt.best.pth.tar'\n",
    "\n",
    "\n",
    "# model_path = 'checkpoint/cifar10_resnet32_LDAM_None_exp_0.01_stage1/ckpt.pth.tar'\n",
    "# model_path = 'checkpoint/cifar10_resnet32_LDAM_Reweight_exp_0.01_stage2_freeze/ckpt.pth.tar'\n",
    "model_path = \"checkpoint/cifar10_resnet32_LDAM_DRW_exp_0.01_stage2_upperbound_freeze/ckpt.best.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc3bd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_s(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (fc): NormedLinear()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_norm = True if 'LDAM' in model_path else False\n",
    "model = models.__dict__['resnet32'](num_classes=10, use_norm=use_norm)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=torch.device(f'cuda:0'))\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09e0e438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "mean = [0.4914, 0.4822, 0.4465] \n",
    "std = [0.2023, 0.1994, 0.2010]\n",
    "    \n",
    "transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "train_dataset = ImbalanceCIFAR10(\n",
    "            root='/media/data', imb_type='exp', imb_factor=0.01,\n",
    "            rand_number=0, train=True, download=True, transform=transform_val)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=False,\n",
    "                                                 num_workers=16, pin_memory=True)\n",
    "\n",
    "\n",
    "val_dataset = datasets.CIFAR10(root='/media/data',\n",
    "                                       train=False, download=True, transform=transform_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=False,\n",
    "                                                 num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cea299b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 64.92it/s] \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "feature_extractor.eval()\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, target in tqdm.tqdm(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = feature_extractor(inputs)\n",
    "        output = output.view(output.size(0),-1)\n",
    "        \n",
    "        \n",
    "        for i in range(output.size(0)):  \n",
    "            all_features.append(output[i].detach().cpu().numpy())\n",
    "            all_labels.append(target[i].detach().cpu().numpy())\n",
    "            \n",
    "all_features = np.array(all_features)\n",
    "all_labels = np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ae4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(feats_, labels_):\n",
    "    centroids = []        \n",
    "    for i in np.unique(labels_):\n",
    "        centroids.append(np.mean(feats_[labels_==i], axis=0))\n",
    "    return np.stack(centroids)\n",
    "\n",
    "featmean = all_features.mean(axis=0)\n",
    "\n",
    "# Get cl2n centorids\n",
    "cl2n_feats = torch.Tensor(all_features.copy())\n",
    "cl2n_feats = cl2n_feats - torch.Tensor(featmean)\n",
    "norm_cl2n = torch.norm(cl2n_feats, 2, 1, keepdim=True)\n",
    "cl2n_feats = cl2n_feats / norm_cl2n\n",
    "cl2n_centers = get_centroids(cl2n_feats.numpy(), all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91bbba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_similarity(A, B):\n",
    "    # input A: [bs, fd] (batch_size x feat_dim)\n",
    "    # input B: [nC, fd] (num_classes x feat_dim)\n",
    "    feat_dim = A.size(1)\n",
    "\n",
    "    AB = torch.mm(A, B.t())\n",
    "    AA = (A**2).sum(dim=1, keepdim=True)\n",
    "    BB = (B**2).sum(dim=1, keepdim=True)\n",
    "    dist = AA + BB.t() - 2*AB\n",
    "\n",
    "    return -dist\n",
    "\n",
    "def cos_similarity(A, B):\n",
    "    feat_dim = A.size(1)\n",
    "    AB = torch.mm(A, B.t())\n",
    "    AB = AB / feat_dim\n",
    "    return AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1198c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 72.77it/s]\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, target in tqdm.tqdm(val_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = feature_extractor(inputs)\n",
    "        output = output.view(output.size(0),-1).detach().cpu()\n",
    "        \n",
    "        output -= featmean\n",
    "        norm_x = torch.norm(output, 2, 1, keepdim=True)\n",
    "        output = output / norm_x\n",
    "        \n",
    "        for i in range(output.size(0)):  \n",
    "            all_features.append(output[i].numpy())\n",
    "            all_labels.append(target[i].detach().cpu().numpy())\n",
    "\n",
    "all_features = np.array(all_features)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e1d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCM acc 90.91%\n",
      "Class accuracy [87.6 94.9 85.  84.1 91.  88.  95.5 94.  94.  95. ]\n"
     ]
    }
   ],
   "source": [
    "dists = l2_similarity(torch.from_numpy(all_features), torch.from_numpy(cl2n_centers))\n",
    "ncm_pred = np.array(dists.argmax(1))\n",
    "ncm_acc = (ncm_pred==all_labels).sum()/len(all_labels)\n",
    "\n",
    "cf = confusion_matrix(all_labels, ncm_pred).astype(float)\n",
    "cls_cnt = cf.sum(axis=1)\n",
    "cls_hit = np.diag(cf)\n",
    "cls_acc = cls_hit / cls_cnt\n",
    "print(f\"NCM acc {ncm_acc*100:.6}%\")\n",
    "print(f\"Class accuracy {cls_acc*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78202a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba3782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluoncv_p38",
   "language": "python",
   "name": "gluoncv_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
